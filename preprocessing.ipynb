{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocessing data for sentiment analysis or text classification.\n",
    "- Using \"Tech in eldercare\" data from JYU as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Essentials (libraries, config, functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "class cfg():\n",
    "    model_name = \"TurkuNLP/bert-base-finnish-cased-v1\"\n",
    "    data_folder = \"/path/to/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class_distribution(df, print_lengths=True):\n",
    "    all_class_dist=[]\n",
    "    for i in df.label.unique():\n",
    "        class_dist = len(df[df.label==i])\n",
    "        if print_lengths:\n",
    "            print('For label {0} there is {1} data samples'.format(i, class_dist))\n",
    "        all_class_dist.append(class_dist)\n",
    "    return all_class_dist\n",
    "\n",
    "def check_token_length(df, print_lengths=True):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n",
    "    x = df[\"text\"].values\n",
    "    \n",
    "    # Encode our concatenated data\n",
    "    encoded = [tokenizer.encode(sent, add_special_tokens=True) for sent in x]\n",
    "\n",
    "    # Find the maximum, minimum, mean and median length\n",
    "    t_lengths=[len(sent) for sent in encoded]\n",
    "    max_len = max(t_lengths)\n",
    "    mean_len = np.mean(t_lengths)\n",
    "    median_len = np.median(t_lengths)\n",
    "    min_len = min(t_lengths)\n",
    "    \n",
    "    if print_lengths:\n",
    "        print('Min length: ', min_len)\n",
    "        print('Mean length: ', mean_len)\n",
    "        print('Median length: ', median_len)\n",
    "        print('Max length: ', max_len)\n",
    "    \n",
    "    return min_len, median_len, mean_len, max_len\n",
    "\n",
    "def create_kfolds(data, num_splits, random_seed):\n",
    "    data[\"kfold\"] = -1\n",
    "    kf = model_selection.KFold(n_splits=num_splits, shuffle=True, random_state=random_seed)\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=data)):\n",
    "        data.loc[v_, 'kfold'] = f\n",
    "    return data\n",
    "\n",
    "def check_dupl_nan(df):\n",
    "    for i in df.columns:\n",
    "        print( 'Duplicates in {0}: {1}'.format(i,df[i].duplicated().sum()))\n",
    "    print('NaNs: ',df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading jyu data for 1st open-ended question\n",
    "df1 = pd.read_csv(cfg.data_folder+'jyudata_q59.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_token_length(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading jyu data for 2nd open-ended question\n",
    "df2 = pd.read_csv(cfg.data_folder+'jyudata_q62.csv')\n",
    "df2 = df2[['text','recnum','vuosi']] #skipping some columns\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_token_length(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for future pseudolabeling, let's edit and save the df2\n",
    "df_pseudolabel_this = df2[['text']]\n",
    "df_pseudolabel_this\n",
    "df_pseudolabel_this.to_csv(cfg.data_folder+'for_pseudolabeling.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating pretraining (MLM) datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining two datasets and picking one column of each (\"text\")\n",
    "df_pretrain = pd.concat([df1, df2], ignore_index=True)\n",
    "df_pretrain = df_pretrain[['text']]\n",
    "print(f\"Dataframe length: {len(df_pretrain)}\")\n",
    "\n",
    "#checking (and dropping) NANs and duplicates\n",
    "check_dupl_nan(df_pretrain)\n",
    "df_pretrain = df_pretrain.drop_duplicates(subset=['text'])\n",
    "#df_pretrain = df_pretrain.dropna(subset=['text'])\n",
    "df_pretrain = df_pretrain.reset_index(drop=True)\n",
    "df_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating data into training and validation sets\n",
    "\n",
    "#creating folds\n",
    "df_pretrain = create_kfolds(df_pretrain, num_splits=5, random_seed=2022)\n",
    "\n",
    "#one fold picked for validation set, others for training set\n",
    "mlm_val=df_pretrain[df_pretrain.kfold==3]\n",
    "mlm_train=df_pretrain[df_pretrain.kfold!=3]\n",
    "mlm_val=mlm_val.reset_index(drop=True)\n",
    "mlm_train=mlm_train.reset_index(drop=True)\n",
    "\n",
    "#dataset lengths\n",
    "print(len(mlm_val))\n",
    "print(len(mlm_train))\n",
    "\n",
    "#saving datasets\n",
    "mlm_train.to_csv(cfg.data_folder+'mlm_train.csv',index=False)\n",
    "mlm_val.to_csv(cfg.data_folder+'mlm_valid.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating finetuning datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and testing sets extracted from df1\n",
    "#let's check NANs and duplicates first\n",
    "check_dupl_nan(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deduplication\n",
    "df1 = df1.drop_duplicates(subset=['text'])\n",
    "\n",
    "#creating two datasets\n",
    "training_data, testing_data = train_test_split(df1, test_size=0.2, random_state=2022)\n",
    "training_data = training_data.reset_index(drop=True)\n",
    "testing_data = testing_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing data distribution\")\n",
    "_ = check_class_distribution(testing_data)\n",
    "print(\"Training data distribution\")\n",
    "_ = check_class_distribution(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving datasets\n",
    "testing_data.to_csv(cfg.data_folder+'finetune_testset.csv',index=False)\n",
    "training_data.to_csv(cfg.data_folder+'finetune_trainset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
